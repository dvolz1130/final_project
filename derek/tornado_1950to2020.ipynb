{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5b3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b323beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/'\n",
    "response = requests.get(link)\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee60e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f12821e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = soup.find_all('a',{\"class\":\"\"})\n",
    "stormevent_details_all = []\n",
    "\n",
    "# For loop to get all the names\n",
    "# Reference code from https://medium.com/@yves.jacquot/predicting-tornado-magnitude-with-machine-learning-c76df84d7872\n",
    "for name in names[7:-2]:\n",
    "        #print(name)\n",
    "    #getting only the files with storm events\n",
    "    if name.attrs['href'].startswith('StormEvents_details'):\n",
    "        filename = name.attrs['href']\n",
    "        storm_url = link+filename\n",
    "        #print(storm_url)\n",
    "        \n",
    "        iter_csv = pd.read_csv(storm_url, compression='gzip', iterator=True, chunksize=1000)\n",
    "        stormevent_details_all.append(pd.concat([chunk[chunk['EVENT_TYPE'].map(lambda x: x.lower())\n",
    "                                                        == 'tornado'] for chunk in iter_csv], ignore_index=True))\n",
    "        \n",
    "combined_tornado_df = pd.concat(stormevent_details_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0bf0d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72693, 51)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tornado_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "795fb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tornado_df.to_csv('data_sets/tornado_data_1950to2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a919bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
